---
layout: post
title: (Day 124) MLx Fundamentals Day 1 - Intro to ML, Naive Bayes, Factorization methods
categories: [traditional-machine-learning,deep-learning,applying-knowledge,theory]
---

## Hello :) Today is Day 124!
A quick summary of today:
* Introduction to Machine learning by Volodymyr Kuleshov from Cornell Univeristy 
* Naive Bayes practical session by Richard Willis from King's College London
* Factorization methods by Cho-Jui Hsieh from UCLA

![image](https://github.com/user-attachments/assets/38224cf5-b969-4972-b252-873584d26d3c)

### Introduction to Machine learning by Volodymyr Kuleshov from Cornell Univeristy 

It was really an amazing introduction. Personally it did not cover new stuff for me, but as an intro I believe it was top. What is supervised ML, OLS, Covered Non-Linear Least Squares, Overfitting, Regularization

### Naive Bayes practical session by Richard Willis from King's College London

The interesting bit was implementing a Naive Bayes classification model from scratch. 

I feel like this is one of the simplest explanations of Bayes theorem that I have seen/read so far (of prior, likelohood and posterior). Richard Willis is a Phd

![image](https://github.com/user-attachments/assets/f83f91e9-0d25-4e25-9950-31c2938f7beb)
![image](https://github.com/user-attachments/assets/3478eca1-5752-412e-9f6c-bd1b957b3c1e)
![image](https://github.com/user-attachments/assets/f1e23bda-0f7a-4689-9e58-46cfdcec01a4)
![image](https://github.com/user-attachments/assets/ecee50a6-4bac-48fa-8df1-cd1f4540a0e8)
![image](https://github.com/user-attachments/assets/cae34390-1bb6-4fe3-87e3-c3a8b1afaf77)

**Implementation**

Computing the prior

![image](https://github.com/user-attachments/assets/25c0d00d-9427-4b63-a4b1-b95cd9d133b9)

Computing the likelihoods 

![image](https://github.com/user-attachments/assets/4995337c-5c32-47c6-bb3d-e3dd965f27f5)

Computing log posterior

![image](https://github.com/user-attachments/assets/639352a9-db2b-4d03-b2ad-0dab6415b127)

Complete NaiveBayesClassifier

![image](https://github.com/user-attachments/assets/dc62e379-50d5-4f17-a62e-acf1a5305d03)

### Factorization methods by Cho-Jui Hsieh from UCLA

I went over the recording and took notes.

Covered topics:

Matrix factorization approach, Altering Least Squares, SGD, extreme multi-label classification, two-tower models, low-rankness for efficient DL, param efficient fine-tuning

![image](https://github.com/user-attachments/assets/f8a5bdb8-65ed-4420-bd16-b62a02811cde)
![image](https://github.com/user-attachments/assets/9aa7cf54-b0d7-4f5b-8289-1cd905186b34)
![image](https://github.com/user-attachments/assets/91e58392-4956-4649-8832-67846b210c6f)
![image](https://github.com/user-attachments/assets/896f3024-d532-41f2-850d-873e0158a5e1)
![image](https://github.com/user-attachments/assets/b9feb7e5-5c1e-4870-a268-8bea7f13d280)
![image](https://github.com/user-attachments/assets/590da58a-5535-4a87-a4d7-348a57db5f5d)
![image](https://github.com/user-attachments/assets/fda11df9-a669-4f0c-b981-47b1d5b77d43)
![image](https://github.com/user-attachments/assets/12683a6c-a1c7-47e8-9d5b-9c0668a0e794)

I am writing this blog in the break of Day 2. I will share what Day 2 of MLx Fundamentals is about tomorrow.

That is all for today!

See you tomorrow :)
