---
layout: post
title: (Day 30) 
categories: [deep-learning, cnn]
---

## Hello :) Today is Day 30!
A quick summary of today:
* covered the last bit of the [CNN course](https://www.coursera.org/learn/convolutional-neural-networks/home/week/4)
* first day of [KCSE 2024](http://sigsoft.or.kr/kcse2024/)

### Firstly, the last bit of the CNN course

It was about face recognition and neural style transfers.

_Face recognition_

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/41999682-7d92-4ae5-9acc-9d9d835c2e48)

You need to be aware of the difference between recognition and verification.
Verification is the process of showing a face and verifying that it is the person by comparing it with the image of the person in the system.
Recognition is the process of showing a face and verifying that a person's face is among all the pictures in the system.

**How do we evaluate a face recognition model?**

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/efc3369d-8ac1-405d-9317-923b220dfd17)

**How do we compute similarity?**

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/56490cfb-bc6a-4669-af7f-9b4a2a0b6597)
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/4f119864-6118-4b57-9385-6ff47e05c0b7)
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/6fba6ad6-ec65-4733-a8e6-10aef7a14517)

You can give all the pictures to the same model, compare the data of the last Dense layer, and calculate the loss function in that way.
There is also a variable alpha. This is to use three pictures at a time and anchor A (self image), positive P (other self image), and negative N (fake image). The accuracy of the model depends on the size of max between 0 and the difference between the absolute values of A-P, and A-N, and adding alpha. High means that the model is more certain when the model recognizes or rejects the face.

We can also use logistic regression

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/8edd2c21-e2f8-4929-8481-ba8b5a36b236)

_Neural style transfer_

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/c8af9d88-bc28-446e-9e7b-43d0ac5d830a)

We give images C and S to a model, and the output is a image C with the style of S applied to it.
The loss function is to calculate the difference between C and S image features.

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/c8142091-3a48-4344-8703-773857ab638e)

And finally ~

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/3ce6ea08-fa1b-48b4-afdf-b787195948fe)

### Secondly, KCSE 2024

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/d1df2ad8-e96d-45bd-90c7-f55c7f497468)

I couldn't take notes a lot today, but the seminar I listened to was
ChatGPT and LLM
- LLM looking back from a software engineering perspective
- Troubleshooting Use Cases in Software Engineering Using LLM
- The Power of LLMs Across the Entire Section of Software Engineering
- Presenter Park Jae-ho (Rainbow Brain Co., Ltd.)

- - LLMs and Software Engineering - History, Landscape, Outlook
- Presenter Shin Yoo - KAIST

I got a lot of materials to read, but the most interesting things are:
* [On the naturalness of software](https://people.inf.ethz.ch/suz/publications/natural.pdf)
* [Large Language Models for Software Engineering: Survey and Open Problems](https://arxiv.org/abs/2310.03533)

<br/>

That is all for today!

See you tomorrow :)

[Original post in Korean](https://50daysml.blogspot.com/2024/01/day-30-day-1-face-recognition-neural.html)

