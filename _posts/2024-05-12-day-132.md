---
layout: post
title: (Day 132) MLx Fundamentals Day 4(1) + CS109 - Fairness in AI
categories: [theory,deep-learning]
---

## Hello :) Today is Day 132!
A quick summary of today:
* last night was the final day 4 of MLxFundamentals
* covered lecture 26: fairness from Stanford's CS109

Schedule was (time is in BST):

![image](https://github.com/user-attachments/assets/d41f588d-e05e-43f0-b9c8-19967ba4f4d4)

The practical session on GenAI (Vision&NLP) was too late for my local time so I will rewatch the recording and share about it in tomorrow's post.

Firstly, Meng Fang from the University of Liverpool

The lecture was a general intro to LLMs

![image](https://github.com/user-attachments/assets/e976b5d2-8b9b-45c7-bc17-0cb53492c932)

Examples for coding, art, Q&A. Then talked about GPT, and the transformer architecture. 
Then, some prompt engineering strategies (zero-shot, few-shot, chain-of-thought, self consistency)

![image](https://github.com/user-attachments/assets/4ccc8d6b-230e-414d-8f67-288a36e88a7f)

Then, a brief intro to retrieval-based models. It was mostly based on the ACL 2023 talk which I covered around Day 74.

Finally, language agents. It was a lot of content for just 2 hours, but it was a nice overview.

![image](https://github.com/user-attachments/assets/df0445f8-2f08-43b7-baad-d81555bcc929)

### Secondly, about CS109 Lecture 26 on Fairness:

Professor Piech introduced the topic of fair AI, and how we need to be aware of the problems it can cause if it is biased.

![image](https://github.com/user-attachments/assets/c95e72bb-3332-41e0-9818-ed2b4f11d474)
![image](https://github.com/user-attachments/assets/87e1955f-99e2-4c9d-b3f5-c84835620bad)

There are two philosophical views on fairness
* Procedural (fairness through unawareness turns out to be hard)
  * focuses on the decision-making or classification process, ensures that the algorithm does not rely on unfair features
* Distributive
  * focuses on the decision-making or classification outcome,  ensures that the distribution of good and bad outcomes is equitable

![image](https://github.com/user-attachments/assets/ba6b952a-fc34-44f7-8814-084241ff115f)
![image](https://github.com/user-attachments/assets/8d0050f9-7fab-4b18-b477-c6c19cd7095d)
![image](https://github.com/user-attachments/assets/6d3055a1-4dba-450f-a011-a724d3634407)

Fairness through awareness still fails to capture certain aspects
* if the classifier is significantly less good at identifying candidates (i.e. for a surgery in a minority group, relative to the data), the candidates accepted might have worse outcomes, leading to future bias
* quality of service disparity might then lead to an allocation disparity (looking at differences in groups and assume there is a stronger differences than there are between the groups, which can change people's mindsets to think that one group is stronger than the other)


That is all for today!

See you tomorrow :)
