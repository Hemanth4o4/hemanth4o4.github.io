---
layout: post
title: (Day 153) First steps into orchestration and ML pipelines (module 3 from MLOps zoomcamp)
categories: [applying-knowledge,mlops]
---

## Hello :) Today is Day 153!
A quick summary of today:
* started [Module 3](https://github.com/DataTalksClub/mlops-zoomcamp/tree/main/03-orchestration): Orchestration and ML pipelines from the MLOps zoomcamp

It is my 26th birthday today, so my study time was pretty limited and studied during my 2 hour bus rider home from Seoul. 

The below is the full outline

![image](https://github.com/user-attachments/assets/fc4f7a3c-bbf3-4a2a-84b8-0e9429135e72)

I only got to complete 3.1. Data preparation, and below are some pics/notes I took.
So before this, in the MLOps zoomcamp we covered mlflow, experiment tracking and model management. I guess orchestration is the next step which automates the whole data prep, training, testing process (note: I am not sure what else so far). 

The 2024 cohort of the camp, uses [mage.ai](http://mage.ai/) as a free-to-use platform, so today's and the next steps will be done on its platform. 

First it was setup using docker. 

git clone https://github.com/mage-ai/mlops.git

cd mlops

./scripts/start.sh

And a local mage.ai webapp was started

![image](https://github.com/user-attachments/assets/6618f7af-e36e-4282-86e9-e393ff6f774a)
![image](https://github.com/user-attachments/assets/0854b138-84d1-44a5-80e3-0858ff6cccde)

In the 3.1 part we created a data preparation pipeline, and here is the final version:

![image](https://github.com/user-attachments/assets/f43a4810-3568-4581-b14d-99e8ce7ab867)

It is not hard to use, and fairly easy to set up. Each block is a piece of code. For example the ingest block is:

![image](https://github.com/user-attachments/assets/7852e581-cdb4-4237-a5bb-ccb99c0f9320)

It downloads taxi data. Then when we create a next block, following it, it seems to automatically chain outputs from previous to inputs of current block. Below is the second 'prepare' block:

![image](https://github.com/user-attachments/assets/adc72274-11f4-426b-942a-b050cd7db5a0)

And the final 'build' block is where we have the dataset split and data vectorized (using util functions)

![image](https://github.com/user-attachments/assets/d057de79-1b8d-493d-9736-1ce479c69b6e)

I will try to complete the rest of the module in the coming week ^^



That is all for today!

See you tomorrow :)
