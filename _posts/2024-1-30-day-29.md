---
layout: post
title: (Day 29) How to do object detection?
categories: [deep-learning, cnn]
---

## Hello :) Today is Day 29!
A quick summary of today:
* Object detection from DeepLearning.AI's DL course

Today's material is still part of the CNN course.

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/663a8f35-52d5-48bd-8a7a-13d677591c8e)

### 1. Classification with localization
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/b3576f0a-80b8-4974-8a9c-f0df17a00567)

If you give a picture to our model, output also includes the object you looked for and the 'bounding box' coordinates of that object

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/09430688-1368-4175-b23a-a8cb9cd184e1)

For example, y includes [pc, bx, by, bh, bw, c1, c2, c3] and pc indicates whether there is an object or not, and the coordinate diagram of the bx, by, bh, bw bounding box is also a variable of multiple classifications (c1 = pedestrian, c2 = car, c3 = motorcycle).

**How do we train such a model? **

First of all, we can train a classification model to see if there is a car or not, and then we can find out whether there is a car or not using the Sliding Windows detection method.

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/0b6faccd-302e-4719-9c55-96f7fff270cf)

However, it was found that the cost of this method was too high, and a method that could be done with convolution was created.
In the above case, we move the window one by one, one by one, but we can do it all at once with a convolution.

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/3c32cfbd-54f9-4d5d-868a-d706ecc1957f)

### 2. YOLO
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/17b388cb-54e9-4ab7-814c-fb0a1e9a425a)

The You Only Look Once algorithm is one of the most widely used algorithms. It is a fast method that can be processed at once if you give an image.
Using the 'Grid based approach', the picture is divided into several windows and calculates the bounding box and pc of the object in that window.

### 3. Object localization evaluation

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/d224b2c7-804f-4ba1-8731-7de7bda6aae7)

It can be evaluated by the Intersection over Union (IoU) method.
If there is a prediction bounding box and a real bounding box, the IoU can be calculated with area of overlap (yellow) and area of union (blue).

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/74dd5637-7634-4ad9-a390-ef84f707fb2b)
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/6674ae54-314e-41c0-bef0-86e6e89dce85)

In fact, when using the YOLO model, 19x19 grid is often used, so the object may be in various windows, so if the pc (probability of object presence) of the bounding box is not 0.6, it can be discarded.

### 4. Anchor boxes
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/f32d6ad9-1846-47ba-a479-5834d922eabe)

The anchor box concept is, for example, a car is usually horizontal. A person is vertically standing. So if you define anchor box for 2 things, you will include anchor box information in the output.

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/e02fc88d-6faf-492e-b52e-89d3bdfc4622)

And the output is not 3x3x8, but it will be 3x3x(8x2) (there are 2 anchor boxes)

### 5. Regional proposal (R-CNN)
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/728efba1-06d7-43bd-8f49-fb9a70234c8b)

R-CNN is a method of defining and showing different classes as different colours (numbers) rather than dividing them into windows.

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/88221c12-93e9-4fd8-82f3-f42fda9f6bdc)

Below are algorithms that have been found to be faster than R-CNN

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/248a99f9-ba25-4114-81f7-9b435d32a696)
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/43a434b0-992d-4e15-b808-43123bc620d1)

### 6. Semantic segmentation
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/15756b61-7084-4378-bda5-159f4a39904d)

Semantic segmented images can be received by a transpose convolution method without the Dense layer in the normal model (hence it is removed in the pic above)

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/47a3473c-c9c7-4fd7-89d1-2c90db58b790)
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/5880dfd1-e03b-4d09-a743-366c5f1f1577)

This method is called U-Net.

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/75313e3b-2e0e-41f1-9a64-e5ba0376f44f)

The U-Net implementation seems a bit hard right now, so I will take a note to do it later. 

### KCSE 2024

I don't think I can learn much on my own for three days starting from tomorrow at the KCSE 2024 conference, but I will summarize what will be presented at the conference.
My presentation is on February 3rd and I'm looking forward to it!

<br/>

That is all for today!

See you tomorrow :)

[Original post in Korean](https://50daysml.blogspot.com/2024/01/day-29-object-detection.html)
