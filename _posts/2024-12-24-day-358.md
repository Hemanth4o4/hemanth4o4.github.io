---
layout: post
title: (Day 358) Ready to learn MLOps from pros
categories: [mlops,theory,reading-research]
---

# Hello :) Today is Day 358!
A quick summary of today:
* registered for Maria Vechtomova and Ba≈üak Tuƒü√ße Eskili's End-to-End MLOps course
* reading about AI Infrastructure Alliance
* read and listened to a podcast about CRISP-ML(Q)

## Registered for Maria Vechtomova and Ba≈üak Tuƒü√ße Eskili's End-to-End MLOps course

![image](https://github.com/user-attachments/assets/48e9d466-446a-47df-8d5f-6638632e103f)

It took me ~6 hours to register due to bank restrictions for non-Koreans here in Korea... but thankfully at the end I managed to register. Christmas came 1 day early for me üòÜ

## [Why We Started the AIIA and What It Means for the Rapid Evolution of the Canonical Stack of Machine Learning](https://ai-infrastructure.org/why-we-started-the-aiia-and-what-it-means-for-the-rapid-evolution-of-the-canonical-stack-of-machine-learning/)

I saved this article from _The AI Engineer's Guide to Surviving the EU AI Act_ book as it seemed interesting ~

The AI Infrastructure Alliance (AIIA) talk about the need for a standardized, accessible AI/ML infrastructure stack similar to the LAMP stack in the web dev world. AIIA aims to foster collaboration amongst companies developing AI/ML infrastructure software to create this standardised/canonical stack. 

One of the goals is to create a blueprint for enterprises to use for their AI/ML workflows. The below is an early version from one of AIIA's working groups:

![image](https://github.com/user-attachments/assets/f3aff2dc-8656-481d-876a-d2f29811886c)

There are already a few companies that provide a platform that covers many of these blocks. 

**What does the architecture of tomorrow look like?**

Many sources cite this architecture by Google MLOps:

![image](https://github.com/user-attachments/assets/1362dda5-62f8-4879-91c8-ae39a557f9e5)

But as the article authors mention - it is missing Data - the key behind AI

_Where are they storing the data?  What kind of system are they using to access that data? How do they control access and version it?
They don‚Äôt include a storage and data versioning layer at all. The diagram picks up at ‚Äúdata extraction‚Äù assuming you already have data storage and scaling perfectly handled._

The above have their structure looking like a combination of multiple pipelines. However, models are never 'completed' - they (need to) evolve constantly to match their changing surroundings. 

_There‚Äôs a continual learning cycle that happens as new data comes in and the model updates its understanding of the world and the new model gets deployed to production and the old model gets sunsetted._

**A better diagram by Larysa Visengeriyeva**

<img width="996" alt="image" src="https://github.com/user-attachments/assets/fef6ec55-0318-46a5-b8f2-6954a44f4c1d" />

It captures the looping nature of the workflow much better than a linear diagram

**The Future and Beyond for AIIA**

_In the long run we‚Äôre looking to deliver the Kubernetes of ML, something that abstracts away all the concepts and communications between different layers of any kind of complex AI/Ml stack people can dream up._

Their goal is to enable plug-and-play and *open-source* functionality for AI/ML systems that are flexible, fast, and agnostic to the underlying technology - making sure we don't end up locked by vendors. 

They don't seem active on [YT](https://www.youtube.com/@ai-infrastructure-alliance/videos), but I subscribed üòÜ

## [Towards CRISP-ML(Q): A Machine Learning Process Model with Quality Assurance Methodology](https://arxiv.org/pdf/2003.05155)

I saved this paper from the same EU AI Act book as well. In the book the author referenced this CRISP-ML(Q) framework and I wanted to check the paper ~

_Organizations expect to double the number of machine learning (ML) projects within a year._ - the increase in models in various industries demands a standardized process to improve project success rates and efficiency

They talk about the *current* framework - _CRISP-DM focuses on data mining and does not cover the application scenario of ML models inferring real-time decisions over a long period of time_

<img width="821" alt="image" src="https://github.com/user-attachments/assets/8dae036e-cbf9-4238-8f6e-ca8b2f934cc4" />

Here is a comparison between the two:

<img width="366" alt="image" src="https://github.com/user-attachments/assets/4abf37df-c333-4dec-a1c0-7aa4de8d504b" />

CRISP-ML(Q) focuses on a 6-step approach:

1. Business and Data understanding (merged): defining business & ML objectives, data collection, and feasibility assessment
  * define the scope of the ML application
  * success criteria (business, ML, economic)
  * feasibility (applicability, legal constraints, requirements on the app)
  * data collection (data version control, cost, time)
  * DQ verification (data description, data requirements, data verification)
  * review of output docs
2. Data prep: cleaning, constructing, standardizing, and selecting relevant features
  * select data
  * clean data (noise reduction, data imputation)
  * construct data (feature eng, data augmentation)
  * standardize data (file format, normalisation)
3. Modeling: selecting appropriate models, incorporating domain knowledge, training, and assuring reproducibility
  * literature research on similar problems
  * define quality measures of the model
  * model selection
  * incorporate domain knowledge
  * training
  * using unlabaled data and pre-trained models
  * model compression
  * ensemble methods
  * reproducability (model, result, experiment documentation)
4. Evaluation: validating performance, robustness, explainability, and comparing results to success criteria
  * validate performance
  * determine rebustness
  * increase explainability for ML practitioners and end users
  * compare results with defined success criteria
5. Deployment: defining inference hardware, testing under production conditions, ensuring user acceptance, and planning deployment strategy
  * define inference hardware
  * model eval under prod conditions
  * assure user acceptance and usability
  * min the risks of unforseen errors
  * deployment strategy
6. Monitoring and maintenance: monitoring model performance, data drift, hardware degradation, and implementing update procedures
  * non-stationary data distribution
  * degradation of hardware
  * need to update any part of the system when needed if we notice some shift, some change happens

CRISP-ML(Q) aknowledges that MLOps is about building systems that can learn and adapt on the fly - data isn't static. 

Quality assurance methodology is introduced in each phase and task of the process model:

<img width="814" alt="image" src="https://github.com/user-attachments/assets/f83ed2de-f4d8-448f-b83d-cfa5134b5936" />

## Listening to papers in podcast mode

There is a feature in [google's notebook LM](https://notebooklm.google.com/) that takes your data sources (1 paper pdf in this case) and makes a podcast-like talk about it. There's also an interactive mode in beta where you can click join and ask Qs as if you are part of the podcast 

<img width="1506" alt="image" src="https://github.com/user-attachments/assets/7f6fa225-89fd-4439-b090-713d9af38323" />

Absolutely amazing. 'Reading' research has never been easier üòÜ

---

That is all for today!

Happy Christmas Eve!

See you tomorrow :)
