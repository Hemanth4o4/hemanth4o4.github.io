---
layout: post
title: (Day 61) Stanford CS224N (NLP with DL) - Machine translation, seq2seq + a side CDCGAN mini project
categories: [applying-knowledge,theory,practice,cnn]
---

## Hello :) Today is Day 61!
A quick summary of today:
* Covered [Lecture 7](https://youtu.be/wzfWHP6SXxY?list=PLoROMvodv4rMFqRtEuo6SGjY4XbRIVRd4): machine translation, seq2seq, attention from Stanford CS224N
* Tried to make a conditional DCGAN to generate MNIST numbers [(colab)](https://colab.research.google.com/drive/182I_gBSORJfNdVZuxcBYKFNxo0gNNLFx?usp=drive_link) [(kaggle)](https://www.kaggle.com/code/divakaivan12/cdcgan-mnist-number-generator)

I will first cover the GAN story
(then will share my notes from the lecture)

So... while watching and taking notes today, I started thinking, what if I can use my notes as data to a model and afterwards, when I want, I can give it raw string text and it will output text in the format of my notes (with my handwriting).

Well I started looking around and actually the first model architecture that came to my mind was the GAN (specifically conditional GAN) - I remembered there was a GAN architecture that alongside the pictures, we can give it the labels, and then on-demand generate. In retrospect, there are of course others, but I decided to go with GAN. 

For maybe 2 hours I busted my head trying to make a simple model with the EMNIST dataset (english characters), and I kept getting weird input size issues. And after a bit I read online that the num of classes for the EMNIST from PyTorch is a bit weird (i.e.). What is more, I saw this: 

![](https://blogger.googleusercontent.com/img/a/AVvXsEgNsRHOFYgkTUIo1ZMQt2aZbago04ZZQ27lsuMOaL3s69gqgMhDsPzLitWH7FAOckrfGqrkG3A17f_Wh2H-BeQv79r7s5rp9cyUlXmZJE3jTGNyj4WEvEh8eMKCusRnAPb1ImPXnE3JDYZo95V5FXv4_JNIsBkzQ9IrA5GXDdBhb8W4z1o2U2T0LYajOobN)

This image with handwritten text is generated with a conditional deep conv GAN ([repo link](https://github.com/tomWitkowski/EMNIST-CONDITIONAL-GAN/tree/master)). And my mind was hooked on the idea -> I want to do it too. But firstly, I wanted to do it with just numbers, a bit more simple (and not having to struggle with loading the EMNIST dataset). 

Thanks to [Aladdin Persson](https://youtu.be/Hp-jWm2SzR8)'s youtube channel, I got reminded how GAN's architecture works and I had a simple model, and started training in my google colab. After a few hours of adjusting params to optimize training and lower loss, and also doing inference - producing new number images, I had a working model. I was so happy. This felt soo long, at first with the EMNIST problems, and then just getting a conditional DCGAN to work. Aaaand... my colab gpu free time finished in a middle of a run and all was lost because I had not saved any weights :/ I did not even take a screenshot of the generated output numbers I got - and they were amazing, human-like. 
Right now as I am writing this, in the colab, there is no output, but hopefully later if someone reads this, you will be able to see sample results (I will rerun it when I get my free gpu hours). 

But also, I am running it on kaggle right now, will get a generated output pic and go to sleep because it is almost 2am.

![](https://blogger.googleusercontent.com/img/a/AVvXsEhESTy9JKmwJ6SmXFZnmf4cfWdT5S71W8gu1n9OzCycccRMUa1N9Wjn7F-bu9MO3q0bBnVYyjJ4QqPhnnI-xnvqFVWT7R6GFdr3QLJwGU70nIZtW5Z8BQsHGge1u8PcnyZy8X3Y35r6zG6EvxFMiiIOr5BrLcnLDKmvL9-mwnqP2maM6ECib0fxmDH9VceR)

So, this is the result. Not too bad. But in colab I could use tensorboard (there is a way in Kaggle too, but it gives me an error :/ ) ([Link](https://www.kaggle.com/code/divakaivan12/gan-mnist-number-generator/notebook?scriptVersionId=165157007) to the kaggle notebook)

**As for my notes for the lecture 7:**

![](https://blogger.googleusercontent.com/img/a/AVvXsEi84Rwlxve20YMNqV8YpQj7jlcxEQE2I2CRhSa8stLU_L7k03fjbNtd3BIr92im8oGX1cZRAaCUsB0IsAn97fH5LctE2kPnAvV9MycpLxdoGZHXPTJycdVeS7gqgQDpqdH0nXvWbd7I9Nk02HgdzvWldcB2-iNAelLMWu52K1JEKfM67WCF3BAMeY3XK3an)
![](https://blogger.googleusercontent.com/img/a/AVvXsEjrXsptU4mi-uksXYqm0x8XIDzJ4Dm7pGbiUArkD6bOjcUlg3q4rQMaW4GUGBZrZ2iQ12NxpvLBKzQDHBgPAXfC_L28OjOMhyCiI64fHsJKXBU_-A0_sprBOOU-hAAJ0UqJ3oCTUd0YwvvwPXakBfLBpoJ1EpYngzghe2k53BtYsyApTP8-6KLBmDAOA4-u)
![](https://blogger.googleusercontent.com/img/a/AVvXsEizznICqyDCJ2lX4XhlzriZfWSAyMCBXOgVxmNg6OLts_l_pBJ5mFbLsT0Ue0s9_Pl8wwptEAR7A9rxz_jEFBDpe4Z_Bv4K3rVtd9xGHKsIh9tg7d9EJNSJ8WP2OPVIzNqF3obNkuRT9Xg_zHUIbN8wCo0C8HZSmDwSDhnObJUIcLzvW4JJJdfMTM0c9K9E)
![](https://blogger.googleusercontent.com/img/a/AVvXsEgOS_Mt_J8jmspF6AquBiP-Y5f6SBzGJTAlfm9q-l1gaHSTHZBdz_aL8KHL6hdreb-zaIKrZLVAqXQdt96tEfAF250O3ncwL1F_jaUVCfk-rXkSm9hIXxrPNWrP_YClAkvv8UniC3jPirUJNbytbEiPUR11un9xtESPLNid_65GfpP8I9GSMtvi99MYxYr2)
![](https://blogger.googleusercontent.com/img/a/AVvXsEhi3uT-5ULVJlO6grpP5gDaAzFZqSBqGyWTOFqF0MFNctCvGpKUKGs367RkpAMIEDRweBH2GiJGsB7UhYnkl9qJVPtJbuaT67snfEB0mI5QZnPfo8bqa_Jpny9ZjvEKSJfP2RWF0c2IgxMBIG99pkZyMkrkQcQJKlVU0-9iXjqVhwpc_XQUUxVwIrZVCtsL)
![](https://blogger.googleusercontent.com/img/a/AVvXsEgpG72KVWtdTt-hPKcA6kW1WF5rvCL4RKEnlnteYfKOqKXFq05tpEB5vgJQFpWrQsyYhUgih7LSF3g1Oj2xJC6eT6hlGz54xEcgYNdbSvu7hbzjTXk_6CLMvr6oL9S0T9DItJc983tfL3zTEtdDDUFWMZlDgE94jrF6UEY2fejPYiUM6TewL0doMYsq0pZ2)
![](https://blogger.googleusercontent.com/img/a/AVvXsEgeCUCHL9EuB6Ca5JkgRtGEdmgLCgpapiLjn7tA0NMDnpF07NOVV2oUGSOgZaYH7M-bGsR107fGvANsc1oswvrxgyvyH_N1cs2nIXuUdXN66K1SFrE3TAImakYqRUH_SwneOB42_1ON-A1y2sNaTZXg8S8oWBUA73N-bC8aZ6-eSnhYh8JAdI9hYxaVM0B9)
![](https://blogger.googleusercontent.com/img/a/AVvXsEiuGnhGmKexRrUHyS0nkukydWv_FuxWrPBui3GyVOk7_J0o6jljPk6cWicxzehy4nFg1B5lbOZIw56RB88YUDbh-H6zj6hSbd85juQr9aKb8lzh07lCP0LH86vPPIhaLWLZb9BNHwFGzjHygssWeZ69kli44kTeZjVDJSZpVE3lAKPVkO2lzamo8BXo_KGd)
![](https://blogger.googleusercontent.com/img/a/AVvXsEhNgDvslku5giN8ajDjqU-xZ1-xJ9NsD-M8BLxg1CGy646HVLXPRnTtr_dAWMeWu4byZldvhS6Ar6VpRVlFyjTMq01mFe0thUIrmnS2oERaTncVAMfQnVS8ibtcouDcum63LY06BxGYlNdcqtibFLNs57sl6qW7D7OH04TqNzWYEbYFJdW64hLvqDnfx1Fs)

That is all for today, tomorrow we continue with CS224N! :)





That is all for today!

See you tomorrow :)
