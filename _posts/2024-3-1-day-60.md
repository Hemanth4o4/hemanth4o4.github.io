---
layout: post
title: (Day 60) Stanford CS224N (NLP with DL) - Language modelling, RNNs and LSTMs
categories: [nlp,theory]
---

## Hello :) Today is Day 60!
A quick summary of today:
* Covered lecture [5](https://youtu.be/PLryWeHPcBs?list=PLoROMvodv4rMFqRtEuo6SGjY4XbRIVRd4) and [6](https://youtu.be/0LixFSa7yts?list=PLoROMvodv4rMFqRtEuo6SGjY4XbRIVRd4) from [CS224N](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/)
* Attempted [assignment 3](https://github.com/divakaivan/a3) - Neural Transition-Based Dependency Parsing

So far, including today, the lectures have been just phenomenal. Based on my previous NLP knowledge and now with these lectures that dive deeper into how modern language models came to be - I am establishing a solid foundation.

My notes from the lectures are below:

**Lecture 5: Language models and RNNs**

![](https://blogger.googleusercontent.com/img/a/AVvXsEifWdjGMwNLKE-26OEwGiswg3sBVbb0bsdvo5crZ6aNQOh1jZ8Sp6jDK1OCGWDDiUMzrIwbdBUHobEkXGPf7B53ZWK7buKkTwAWRGuratOylCa5lRQBgus6DpQjj3qWUcFq5CahXvxAJIxNz_xZ32L2POGffRxAYbTNL0SI2FdvhkBcASNnCkHTmAQGRsxe)
![](https://blogger.googleusercontent.com/img/a/AVvXsEj_jP9UDfcpXBNF8ocKQy6-gk31A5iOarOBFohXADJvRXfNCc90RN-rCBlaZjboIEUG-WDQosK88IgMnLBmn5NpDi9kf5olF-ON0kiJKHh3iQo2MKTqaUUILEdFnBcFH7WcFSsmdaMTSk1KtmPGYLyCGJEBWiagmpPSIkc5kZ8miy-dpiVQNi4BGtKoMA5O)
![](https://blogger.googleusercontent.com/img/a/AVvXsEiHeFm6wlSTDWDR2UZf__10H61C4GM6dZVT67pehzJxjPYnx3SLMKvRwVMt8GBjeadqRzoKynFcLyQ2U1uY1pMw4bkBRbDxwIlGNR1ss9HceGgRkpoQzVocxHlARCboj-2TZ22iRy1YnY2_uQHs-gF4U9X_zxEFNXkKUZ4otwB5xIUUTfWG1FmfpNZ2-SQm)
![](https://blogger.googleusercontent.com/img/a/AVvXsEh9q9oAB2Ou98YMB7tKRtuzHBhkJWDZB53eNng2eO5TJ96gCflynl1FYhnSDxZlTxTmSA0lpqHBVMp7eAYHgTmnE6k7Jn2Mg-0H8rpRdefYi3MfPlQsDBx9vzER5TEYiucLC_XIllKdh_sdtf4ETmaSLHIRiDDrDhhD4pwJ6tZLDzdZNqTYZ8BTxAJZ5wcG)
![](https://blogger.googleusercontent.com/img/a/AVvXsEhBRN4GL0Ps7Q1UiS0PYiUjwd7S-g0FMdzxv8foxcfQB1Xc7lb0mhzbXWK6_hU4GbtgFDW3pHXi7TgUkTQmcmUcoeUlL2dbfqK2QYgegioFSCBpjGj6ieiYn4A_ns1hnvrE3FUWlJxwsuV2Es669N8CTnmoedvMhZpO-iUKm3MKf4GoT02I---mME1mtS5T)
![](https://blogger.googleusercontent.com/img/a/AVvXsEjKKZW9ukwpRf5ih7-Cu-Dyc78VZLBnDPm0408OSDKRA5M2KzP2g9NumpnQlsubE4MsZPnbRXEBty5NhoKDhdClYOvR1FRMbweW25raA5pKod7SK0FvWawFkh21iU9_KVnkgk4x02FZDy52reLebjRzWZxyCFbDRRILWJDUhmOYGtBUqj8rEoB_j4amAC12)
![](https://blogger.googleusercontent.com/img/a/AVvXsEhCngZFHPF0H-akX0DOwn6YfRg7x-yv6u9nAyo_w4a4OEJDn5w4mmSeAZQDsQmysZW9RqfewrD4gXF8qU2LvXJPHPmNu1YK8SKr_Gm1M-VikNcRImEPLwq44oWp9HQXABsvD05ectJH_OH9vBAwBZafhJY3kIm1N6rniaRJZruQzcs6Z9XeUfi0bK02wBwx)
![](https://blogger.googleusercontent.com/img/a/AVvXsEjMKnUFOPhbwUnd9K0wHibJ_g9VSL3DSrfjtblSXEK3jMGEu_fa25bizSdn03RAVm25-V_kATeWvm1IhwchMRSswSVZ9QqmLWq66AejE6V0ihBSn09jgM3JmO3npfRzRCcAUWpTyMkebcaxuMbYt3Vq7Dn0tQ6IHeyYRkaMk6ek3qs4yBDrugzbFcEaXKt4)

**Lecture 6: Simple and LSTM RNNs**

![](https://blogger.googleusercontent.com/img/a/AVvXsEiYCr2DdCJ15EWG9CCcXPq06p04zBNy2IZiK0RaLJ75D9a6rg9rrCOBO_W8SAiT6oAiLwt6o7YkydjEF3u6ZmBXwhky6aU5TVATFV7-cSDZArlkDmszsUFjtgj4yQx2NTKm31RLa0vVaH-JYEINozlRYe6PNKqF6KpTQuT1Y1CMzbnrV6QqH0t9MAtwt_UP)
![](https://blogger.googleusercontent.com/img/a/AVvXsEh6IDP0fCmHj2PntECgUAB8JWNNmO3sV-Vt05Ax5fpaa8C6Q_8NDf5flE1gGL6zcWmb-TqcJobMo7r9ifv1srXalkatUoU3Gsw2XuKqjOH1XaWKj_QITsSGkHWEJUyzrTD9nBSa7ch8xxI1ACxZJwljvh2-yup3dvZin_7_e0WC9HuLw25r0Zdrk17ATtdF)
![](https://blogger.googleusercontent.com/img/a/AVvXsEguGZ8jxC_VcRKqm182PdcJ7B4M5Pb4GVszY-zKhbcxOMTeUMHq7rkHunC_4NfIiw91mCc0qnwo4K_QoWN99dTxEKAWuOOWr3JqFVD7d--B6OgaDakOmuDJxQVehz1Q8YFSPlJZ2dwIFgM4ptu8dbDmcmdxCGEg9JqTjWGl3fdAtGnw2A9nDw_3rKaOuOG-)
![](https://blogger.googleusercontent.com/img/a/AVvXsEg6Zbw7Yr_JjM4_pauyqxV_5HaQIDqhLyfeorgmO91N416prF46Q2Iy8v-YHlFoNmlwpuUxz_hqb70M8EFt26cN0EdMUsowmW-Qbmt5WBnyrMORbh1lIfwjfPCj3JlGQEr8OOMIM7uhOCIfqtOwn3hNbNx4R_hY1GD82-q04x-0Tamn8oRClJUWbm-2Prqz)
![](https://blogger.googleusercontent.com/img/a/AVvXsEj8nZwc1VgQ5uxKkQ2sqj9pLzF1GXB7lGe0uqoFtsqkrfgXlKch5sdKBbHtihSkB6Lev2ojAZIzWS2zIgLx_eADDu2aUAFEMz19v-W4NjowR8pHxdB2qw7sDng92ARecyygzkiNog84g7wXL_0uSriHfVPwzGRESHjO1FSFThZVR5GDFeBtJcsVLvJ-nzX5)
![](https://blogger.googleusercontent.com/img/a/AVvXsEhpvKHnF6vW1zWWW-xLAR8z1Ezyj4zT3LpH9Q91lFD3SKT6XVuTb49EnfRB_PSckMLGVC2U3nXs_uv3i57pTzdtngWEYV7_CTTXlIr4VeQhKyBFTqkaG326vZRrwa6TmFf4z8j271r5skyOF1mMkGoVvqWVm6kkQrtecpGYDTlaaT65r_LJU1_TwtZjXlr_)
![](https://blogger.googleusercontent.com/img/a/AVvXsEi-xkEDKBHipbJahhvuXG29PgkzQaqKlEPt_6EKP3N4wBuX48y6JbLdD7ssjz1QtdQg16-Dc3hKxMPAw-PF8il2wq5mQXH03oUCic6XjFlAWXomdATizuOX_1bs0MRG74jCju0vJo554QE--KkPkBq2MN7riU79l8JGBFhEYvv4Jw3iraVlHdbU2D4fWq5w)
![](https://blogger.googleusercontent.com/img/a/AVvXsEjx9pZbvDjTRvsn_cpQiyttiwRHDKd2TwPKfaKsh8WeAK574S-MaAh41YrWmbD5ctnvHusieyDvg33T41rOPaTKfFnKENsYy2h4epTaV_FmYhRwCD-w0hrEJ_tKB2cQI-1HjQKkO3GlBUkBuB8GCVV6O-h0TQlAsX0JKFMJG9uBGsf1ISi4-ymqeYIDvtTw)


Tomorrow's turn is Lecture 7: Machine Translation, Attention, Subword Models and Lecture 8: Transformers depending on lecture 7's length and readings.





That is all for today!

See you tomorrow :)
