---
layout: post
title: (Day 160) Simple data engineering pipeline with Prefect, and... MLOps with mage.ai (tons of problems)
categories: [mlops,applying-knowledge]
---

## Hello :) Today is Day 160!
A quick summary of today:
* simple data engineering pipeline with prefect
* tons of trouble learning about orchestration with mage.ai

After yesterday's journey with prefect the youtube algorithm recommended me [another tutorial for prefect](https://youtu.be/FxRZ9zo6GmI) - this time for creating data pipelines with prefect. So I decided to give it a go. 

What is data engineering?

![image](https://github.com/user-attachments/assets/94d0dc42-06d7-4f7e-9e27-0e47b2770513)

* data scientists can do data engineering, but in specific cases where the two jobs cannot or are not needed to be separate
* data engineers build databases, they build lots of data pipelines and manage infrastructure (also care about cost, security)

What are data pipelines?

* ETL(ELT)/batch pipelines that move data from A to B
  * databases, APIs, files
* streaming pipelines - as data comes in, we consume that data and send it wherever it needs to go 
  * message queues, polled data

The main github repo used is [here](https://github.com/CodeSeoul/intro-to-prefect).

After some basic setup, when we run 'pipeline' in the terminal which runs the main.py file:

![image](https://github.com/user-attachments/assets/6a5b9994-f13e-4a45-97d8-1e687053ced1)

In prefect we get a flow run

![image](https://github.com/user-attachments/assets/af2dff44-70d6-4927-87bd-82e33c855bfb)

and logged outputs from the petstore url

![image](https://github.com/user-attachments/assets/6b52d79f-5fe0-4478-8ca7-be52b10e8948)

Now for a flow with a bit more tasks~

1st task: retrieve from API

![image](https://github.com/user-attachments/assets/9b4f8c53-c77c-496b-9251-09e7500c0106)

2nd task: clean data

![image](https://github.com/user-attachments/assets/32b3fe36-2633-4c1b-89cf-25ddc331f1b3)

3rd task: insert to postgres db

![image](https://github.com/user-attachments/assets/a9da4e5f-07ab-47db-b866-f2a3f245cbb4)

final flow:

![image](https://github.com/user-attachments/assets/24f4d5ff-64d5-4225-be5a-2d4d8971398a)

Success!

![image](https://github.com/user-attachments/assets/6d4bc67c-906e-4bf7-b7e4-b66ef2d1ae9a)

We can also see the data loaded into postgres:

![image](https://github.com/user-attachments/assets/233e2660-eda0-4269-8564-9bde68645a43)

Beege (the teacher) showed also how to do simple task tests and avoid a common prefect error when executing prefect task functions outside a prefect flow

![image](https://github.com/user-attachments/assets/a9511af6-f209-43b6-bcb1-3c5d22cca370)

Prefect is amaing, but the MLOps zoomcamp course works with Mage.ai this year, and after I gave up on it due to errors that I could not fix last time - I decided to give it another go today. And... omg so many errors and problems - I almost gave up on it several times. The videos are recorded 2 weeks ago, and yet there is so much different on my UI (and other students' UI) that it is mind-boggling.

The content was not much, but the constant errors... made me invest upwards of 12 hours of bug fixing for a total of 30 minutes of video content. 

### Orchestration with Mage.ai from MLOps zoomcamp [module 3](https://github.com/DataTalksClub/mlops-zoomcamp/tree/main/03-orchestration)

The content of the intro to orchestration is:

![image](https://github.com/user-attachments/assets/d56f3cfc-2641-409a-9785-282f114e050e)

I have to do 3.5 tomorrow (hopefully). 
I just want to say a huge thank you to the QnA bot on the mlops zoomcamp slack channel that at least pointed me into the right direction to solve my issues. Just quickly - I am bit sad that there are so many issues (almost every video) because it will drive people away from this amazing course, and below I will just provide my successes, and if you are really curious about my problems - they are all on the datatalks slack channel haha. 
I started from the beginning

3.1 Data preparation

![image](https://github.com/user-attachments/assets/f5600cea-7178-436e-8331-5827d9e29e5b)

I created the above pipeline that reads NY taxi data, does a bit of preprocessing, and then outputs X, X_train, X_val, y, y_train, y_val, dv. By the way, each block is a piece of code.

3.2 Training

First, create a pipeline to train a linear regression and lasso model. It takes data from the above 3.1 pipeline, loads models, does hparam search, and finally trains the two models.

![image](https://github.com/user-attachments/assets/c02497da-9d37-4379-863f-21482267a367)

Secondly, I had to create a pipeline for an xgboost model

![image](https://github.com/user-attachments/assets/a6decd1b-0ac9-4579-87d0-b13a1affb7ea)

The last (pink) bit is connected to creating visualisations. 

3.3 Observability

![image](https://github.com/user-attachments/assets/b63c3a7e-bcce-41c9-a76b-952b7fae88d2)

We can create any kind of bar/flow/line/custom charts, and the above 3 are some SHAP values from the xgboost model. 

3.4 Triggering

Here I created an automatic trigger to train the xgboost model when new data is detected.

Also, created this predict pipeline

![image](https://github.com/user-attachments/assets/c9b089ac-1da9-4791-8c39-3876acdbbed5)

There is a nice way to setup a basic interface for inference

![image](https://github.com/user-attachments/assets/535f95df-5cc2-4e15-8cc7-2bf6a0db9a4b)

We can also setup an API to do inference through that as well:

![image](https://github.com/user-attachments/assets/604a9c8b-39cf-4368-9bbb-d69e46d34710)

That was all for today. I have very strong feelings towards Mage.ai but for now I will roll with it because of the nice course. Otherwise I will try to use prefect for some side project (have to think about that a bit). 



That is all for today!

See you tomorrow :)
