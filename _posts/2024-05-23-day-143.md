---
layout: post
title: (Day 143) Forward, backward prop and param update by hand
categories: [math,applying-knowledge,deep-learning]
---

## Hello :) Today is Day 143!
A quick summary of today:
* did forward and backprop of a toy neural net by hand and confirmed with python
* set up my station at the student lab at uni

The idea of doing backprop manually again came back yesterday night. But this time I wanted to do it 'as in the old days'. In one of the lectures of CS109 Professor Chris Piech said he used to do forward/backprop manually back before autograd, so I wanted to experience that as well (in a toy example). 

Below are my handwritten notes of the forward, backprop and param update for the 1st iteration of a toy neural net. 

![image](https://github.com/user-attachments/assets/6b907786-0641-4d38-a63f-107ccca7ae5c)
![image](https://github.com/user-attachments/assets/4bbc4170-40ce-4894-b8f6-28403d3de154)
![image](https://github.com/user-attachments/assets/ccbb8356-4895-4437-9abc-d0c5e56a4ab0)
![image](https://github.com/user-attachments/assets/7748559c-ecdd-4e00-b0bf-033a3e3e7b70)

My tablet battery died towards the end so I wrote it on the board.

![image](https://github.com/user-attachments/assets/7998ab2e-38c9-4690-935a-a21166d9dba0)
![image](https://github.com/user-attachments/assets/19f7149b-ece8-4e97-9976-077aff861927)

I confirmed all the numbers with python - the used notebook is [here](https://github.com/divakaivan/neural-network-from-scratch/blob/main/toy_nn_from_scratch.ipynb).

As for my 1st day at the lab
I liked it. It was mostly waiting for downloads and setting up cuda/torch/python/etc because it was a new PC. There was a seminar where 2 of the students talked a bit about what they are doing.

At the end of the day, I had a chat with Professor Park about potential competitions I can join and he can help me. So it is something to look into tomorrow. 



That is all for today!

See you tomorrow :) 
