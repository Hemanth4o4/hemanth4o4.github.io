---
layout: post
title: (Day 10) Simple linear regression to predict GCPA
categories: [applying-knowledge]
---

## Hello :) Today is Day 10!
A quick summary of today:
* House price basic prediction model comparison on [Kaggle](https://www.kaggle.com/code/divakaivan12/house-price-basic-prediction-model-comparison)

**Data**

![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/9a73bcdd-212c-4ce6-9fe1-ce24549741af)

Majority was categorical data, so I used `pd.get_dummies()` to prepare them.

**Some viz**

* Area and price correlation 
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/6580ed06-ac3d-4b15-9f3b-90e147c9c0a3)

* Outliers
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/16b9cdd4-23b3-43d6-9600-5e5783800e69)
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/c2b194ae-dbd9-495e-903b-9365934c02cc)

I used z-score or IQR to deal with them. 

**Top features**

I used the correlation table to find the top-10 features that correlated with price
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/a4cb96af-2b4d-4968-abad-9d6a453007c2)

**Model creation**

I using LinearRegression, DecisionTreeRegressor, RandomForestRegressor, XGBRegressor (wanted to compare results)

**Results**

LinearRegression - Train MSE: 0.81978 | Test MSE: 1.37829

DecisionTreeRegressor - Train MSE: 1.06803 | Test MSE: 1.64172

RandomForestRegressor - Train MSE: 0.91908 | Test MSE: 1.41498

XGBRegressor - Train MSE: 0.26813 | Test MSE: 1.60890

Lastly I tried using some Polynomial features, and the results are:
![image](https://github.com/ivanstudyblog/ivanstudyblog.github.io/assets/167014511/201e4d49-f3e4-47d9-a172-a08d514a0dd2)

I spilled boiling water on my finger, so writing this post was very hard :( 

That is all for today!

See you tomorrow :)

[Original post in Korean](https://50daysml.blogspot.com/2024/01/day-10.html)
