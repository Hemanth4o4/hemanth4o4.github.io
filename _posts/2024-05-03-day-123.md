---
layout: post
title: (Day 123] Optimization algorithms chapter from Dive into DL
categories: [deep-learning,theory]
---

## Hello :) Today is Day 123!
A quick summary of today:
* read about optimization algorithms, and maths for DL from Dive into Deep Learning

Firstly, my notes from the optimization algorithms chapter

Covered topics:

Common challenges in DL optimization, convexity, convexity properties, SGD, momentum, Adagrad, RMSProp, Adadelta, Adam, LR schedulers

![image](https://github.com/user-attachments/assets/aedb5784-5fc2-4714-b310-2c9320367206)
![image](https://github.com/user-attachments/assets/824d8374-417c-4a0c-9f18-2c54d45c9be0)
![image](https://github.com/user-attachments/assets/8e2ef566-c914-42ea-8461-f1b65a199ab8)
![image](https://github.com/user-attachments/assets/e6b6a1d6-3788-4a2b-a797-c3f6ec4a324a)
![image](https://github.com/user-attachments/assets/f4e2bdf6-24d0-4f60-ae0a-d66861faadd5)
![image](https://github.com/user-attachments/assets/5dcda9c3-aec0-44b4-b242-67c7057dedd6)


### As for the maths for DL

This is actually in the apendix, but I decided to read through it, just to check if there is any interesting math. 

The content is as follows:

![image](https://github.com/user-attachments/assets/439be81a-cc2f-48cd-937c-9721c589f854)

Having this appendix is very nice and definitely helps to answer questions like for example when I went to the roots of multicollinearity (on Day 121) - understanding the math helps understand the root of problems. 



As for the MLx Fundamentals it started just as I am finishing this blog. The first day is from 9pm to 3am in my local time, so I will write about it in tomorrow's blog. 

Schedule (time is in BST)

![image](https://github.com/user-attachments/assets/b3f715c5-1b08-43e1-b50d-988175561100)

That is all for today!

See you tomorrow :)
