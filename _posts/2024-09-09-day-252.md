---
layout: post
title: (Day 252) Designing effective ML monitoring with EvidentlyAI
categories: [nlp,mlops]
---

# Hello :) Today is Day 252!
A quick summary of today:
* covered first 3 sections of module 4

Tomorrow I have an exam so today my study time for this blog was a bit limited. Nevertheless, I got to cover half of Module 4 from EvidentlyAI's course on AI monitoring.

## 4.1. Logging for ML monitoring

What is a good ML monitoring system?
A good ML monitoring system consists of three key components:

* Instrumentation to ensure collection and computation of useful metrics for analyzing model behavior and resolving issues.

* Alerting to define unexpected model behavior through metrics and thresholds and design action policy.

* Debugging to provide engineers with context to understand model issues for faster resolution.

![image](https://github.com/user-attachments/assets/3ee4bbc5-d809-44b8-af53-a214ec9c70d4)

### Logging and instrumentation

Step 1

![image](https://github.com/user-attachments/assets/cd091fcb-9a06-453f-9548-0443a6c8d193)

Step 2

![image](https://github.com/user-attachments/assets/a85536ff-697f-4662-b3bc-a964bb32a91b)

Step 3

![image](https://github.com/user-attachments/assets/226cc5f6-b296-4d7d-94d5-2a32dd84b83f)

## 4.2. How to prioritize ML monitoring metrics

![image](https://github.com/user-attachments/assets/2d5c3144-e56c-4c45-bba9-dd78d7a18da0)

![image](https://github.com/user-attachments/assets/9015044e-f082-4523-9bd4-f965518fbf50)

![image](https://github.com/user-attachments/assets/63956970-c4cd-4fee-b935-f6b0167be5a8)

![image](https://github.com/user-attachments/assets/6749ce96-97df-4661-9ec7-36b7a66e8701)

TLDR for metric prio

![image](https://github.com/user-attachments/assets/14822511-695d-4efa-96a1-f3f136277b66)

1. Service health

![image](https://github.com/user-attachments/assets/85f71c24-c1be-48c4-bf1d-60ed487261f8)

2. Model performance

![image](https://github.com/user-attachments/assets/96626585-e38d-46d6-88f0-f73ea66ae0a2)
![image](https://github.com/user-attachments/assets/86fe709a-aed0-48d6-be9b-f2c5f9974a56)

3. Data quality and data integrity

![image](https://github.com/user-attachments/assets/1abd68da-f7bd-4690-8c6c-9aee366f51a1)
![image](https://github.com/user-attachments/assets/e6f9f5cd-3126-4fc5-8160-d4e53686ec71)

4. Data and concept drift

![image](https://github.com/user-attachments/assets/5947cbbb-4b0b-4bbb-832d-52d66f81dc69)
![image](https://github.com/user-attachments/assets/be46f2b2-cb2f-4c9c-8396-f20ee2ac5fb7)

### Comprehensive monitoring

Depending on the problem statement and model usage scenario, we can introduce more comprehensive monitoring metrics:

* Performance by segment. It can be especially useful if we deal with a diverse audience or complex object structures and want to monitor them separately.

* Model bias and fairness. These metrics are crucial for sensitive domain areas like healthcare.

* Outliers. Monitoring for outliers is vital when individual errors are costly.

* Explainability. Explainability is important when users need to understand model decisions/outputs.

## 4.3. When to retrain machine learning models

### Model retraining strategies

1. On Schedule

![image](https://github.com/user-attachments/assets/5c1e7c3e-8db6-4d03-9d1a-b7acae7daaa0)

Pro-tip for scheduled retraining: use historical data to determine the rate of model decay and the volume of new data required for effective retraining. For example, we can get a training set from our historical data and train a model on top of this dataset. Then, we can start experimenting: apply this model to new batches of data with a certain time step – daily, weekly, monthly – to measure how the model performs on the new data and define when its quality starts to degrade. Important note: we need labels to do it. If feedback/ground truth is not available yet, it makes sense to send data for labeling before we start experimenting with historical data.

![image](https://github.com/user-attachments/assets/8a77cc6a-b4a6-4797-bc48-1617f2662a3b)

2. Trigger-based retraining

![image](https://github.com/user-attachments/assets/eec2b90d-d6c1-4690-907b-6deef85b47f7)

### Model retraining tradeoffs

![image](https://github.com/user-attachments/assets/614b2ac7-71a5-47f9-8ef3-a96747d5a48f)

### Thinking through the retraining decision

Be pragmatic. Develop a strategy considering available actions, service properties, resources, model criticality, and the cost of errors. Here is an example of a decision-making logic you can follow:

![image](https://github.com/user-attachments/assets/e8499952-5cbe-428d-9fdd-8737dad9acc0)

![image](https://github.com/user-attachments/assets/284ab602-e821-4113-97a7-9b1d583a6339)

![image](https://github.com/user-attachments/assets/2794e2cf-8a6b-4916-ae4b-c7ffd19f9485)

![image](https://github.com/user-attachments/assets/c6616793-ef24-422d-b95c-5e03eae5f9a9)

![image](https://github.com/user-attachments/assets/e19ee268-e9c6-4a2f-b54b-b3e52e46c8af)

![image](https://github.com/user-attachments/assets/dcd6be7c-f39a-4b6d-833e-3890ee98f39f)

![image](https://github.com/user-attachments/assets/b4510b23-e0df-4639-996a-a552cd01d65e)

---

That is all for today!

See you tomorrow :)
