--- 
layout: post 
title: (Day 37) PyTorch traffic sign classification and detection model
categories: [deep-learning,cnn] 
--- 

## Hello :) Today is Day 37! 
A quick summary of today:
* [Simple PyTorch animal classification](https://www.kaggle.com/code/divakaivan12/simple-pytorch-animal-classification)
* Traffic sign classification (and localisation)

**Firstly**

to put knowledge into practice I decided to try to make an animal classification model

There are some limitations with Kaggle's GPU so I had to tone down the picture sizes, the augmentations and model complexity.

So ~ 
data augmentation

![image](https://github.com/user-attachments/assets/786406e4-44d5-4949-9a13-05a0890f1e65)

Image example:

![image](https://github.com/user-attachments/assets/12f72eba-592d-48ec-834c-b2c1b36dc97b)

The categories: cat, dog, elephant, horse, lion

I divided the data into batches:

![image](https://github.com/user-attachments/assets/d174fdc4-f251-42b7-9ee4-739784ee9b61)

The model is:

![image](https://github.com/user-attachments/assets/6ef88088-efd6-4901-aa26-5c4aa91a28ae)
![image](https://github.com/user-attachments/assets/e26bf73d-4401-4a27-b4c8-e36ce0c6c5e9)

The training took a lot of time; below you can see the last epoch's results

![image](https://github.com/user-attachments/assets/6cdd3091-54f7-4cfa-bd8d-1cfd4fe27ec2)

Example classification:

![image](https://github.com/user-attachments/assets/cb2aa10d-d4b3-4b01-a37f-b21e95df8ae7)
![image](https://github.com/user-attachments/assets/886c769c-7079-4115-b8a7-c0dd20b5a675)
![image](https://github.com/user-attachments/assets/b723efe2-a542-42db-8c89-1ed70a3e5c8d)

(there are some weird classifications too haha)

**Next ~ **

About the traffic sign classification and localisation model

[Here](https://www.kaggle.com/code/divakaivan12/traffic-sign-classification-and-bbox-model-pytorch?scriptVersionId=162144835) is a link to the notebook on Kaggle.

The model's dataset has 43 classes (here are 21 of them)

![image](https://github.com/user-attachments/assets/8a1bdbe9-e1e3-4b76-841e-5f14fff2242d)
![image](https://github.com/user-attachments/assets/589c7158-4a2d-46e6-961d-fe72d3eefb43)

The image size varied a lot so I standardised it

![image](https://github.com/user-attachments/assets/b18f6921-8afc-4a96-9add-b4295db3d01b)

Model architecture:

![image](https://github.com/user-attachments/assets/e6b9b5e5-bc67-40a4-8838-e3658278af30)
![image](https://github.com/user-attachments/assets/11869595-922c-4482-865c-fc5597d754df)
![image](https://github.com/user-attachments/assets/93b9e74c-9ae7-49bf-a3ca-f059baac053e)

I tried various architectures, but the accuracy was not that good, so online I found *AlexNet* and wow ~

![image](https://github.com/user-attachments/assets/15b8f9ce-bde5-4868-9c17-6cd3be215081)

Example:

![image](https://github.com/user-attachments/assets/985708d2-be7c-466c-901c-aa69287bdfbf)

I applied what I learned yesterday to this model according to the vegetable/apple bounding box model from yesterday, but the accuracy and loss won't decrease even after training, and I'll try again tomorrow!!!

Now it's 2.37am and I will go to bed ~

That is all for today!

See you tomorrow :)
