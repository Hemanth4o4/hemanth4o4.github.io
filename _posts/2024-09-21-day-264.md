---
layout: post
title: (Day 264) Day 5 of the DeepLearning.AI Data Engineering Professional Certificate course
categories: [data-eng,theory,applying-knowledge]
---

# Hello :) Today is Day 264!
A quick summary of today:
* continue with week 2 and 3 of [course 3](https://www.coursera.org/learn/data-storage-and-queries/home/welcome)

## Week 2

### Data Warehouses

A data warehouse is a subject oriented, integrated, non volatile and time variant collection of data in support of management's decisions

<img width="917" alt="image" src="https://github.com/user-attachments/assets/8a2d99c5-8448-4557-9fba-570c323903f1">

<img width="930" alt="image" src="https://github.com/user-attachments/assets/80c8986b-3d80-4072-9988-fde2a24d20a1">

<img width="936" alt="image" src="https://github.com/user-attachments/assets/4762ec0e-0ef3-4518-aecf-ae31572698c0">

Data warehouse implementation

<img width="922" alt="image" src="https://github.com/user-attachments/assets/7f81cac5-3f24-4932-9303-609793998de6">

<img width="905" alt="image" src="https://github.com/user-attachments/assets/8becae00-9028-4bec-97db-6e4e3693349c">

### Data lakes

<img width="845" alt="image" src="https://github.com/user-attachments/assets/8eba0d9e-9b95-4d3b-99fd-ea3d2dd2987c">

Shortcomings of data lakes 1.0

* data lakes became data swamps: no proper data management, no data cataloging, no discovery tools, no guarantee on the data integrity and quality
* 1.0 was write-only: data manipulation operations were hard to implement, difficult to comply with regulations (like GDPR)
* no schema management and data modelling (joins were a huge headache)

Next-gen data lakes

In response to the limitations of the original data lake 1.0, engineers have developed strategies to enhance data management and retrieval. This video discusses three main approaches: **data zones**, **partitioning**, and **data catalogs**.

#### Data Zones
Data can be organized into different zones within a data lake, often following a three-zone model:
1. **Landing/Raw Zone**: Stores raw data ingested from source systems, providing a permanent record.
2. **Cleaned/Transformed Zone**: Contains data that has been cleaned, validated, and standardized, with any PII removed.
3. **Curated/Enriched Zone**: Holds data modeled with business logic, ready for consumption and stored in efficient open formats like Parquet, Avro, or ORC.

While the number and naming of zones can vary, they allow for appropriate data governance and ensure data quality for users.

#### Data Partitioning
To improve query performance, data in the cleaned or curated zones can be partitioned based on criteria such as time, date, or location. This technique enables query engines to scan only relevant partitions, resulting in faster performance.

#### Data Catalogs
A data catalog serves as a centralized collection of metadata about datasets, allowing users to search for information based on data owner, source, partitioning details, and column definitions. It maintains schemas and records changes over time, fostering a common understanding of data structure across the organization.

#### The Data Lake House Architecture
Despite advancements, organizations often relied on multiple storage systems to meet various needsâ€”leveraging the low-cost storage of data lakes and the superior performance of data warehouses. This led to the costly ETL process for moving data between systems, which introduced risks of data quality issues.

<img width="924" alt="image" src="https://github.com/user-attachments/assets/89595686-d719-4b31-b67b-ca62ed5e4570">

To address these challenges, the **Data Lake House** architecture was developed, merging the benefits of data warehouses and data lakes into a unified solution.

### Data lakehouse

<img width="770" alt="image" src="https://github.com/user-attachments/assets/db2ac502-aafa-43af-91d6-8e91eae6780b">

<img width="918" alt="image" src="https://github.com/user-attachments/assets/51a99bac-5f79-4c62-8fc0-bfabdb104a81">

<img width="883" alt="image" src="https://github.com/user-attachments/assets/1aabc990-5bb6-480b-98f7-8d7e37ebb849">

<img width="939" alt="image" src="https://github.com/user-attachments/assets/547f6f4e-3162-465a-9ce0-f84e8b51d0d0">

I have seen complaints online and memes about AWS' *many* services. And the above pic from the course definitely confirms to this meme ðŸ˜†

### Summary

<img width="915" alt="image" src="https://github.com/user-attachments/assets/f044d94c-ce94-4f76-9fbf-5e1217c95433">

## Week 3

### Batch queries

There was some SQL practice like:

<img width="940" alt="image" src="https://github.com/user-attachments/assets/1e6a4dc8-d54d-45f2-83b7-665bd05c5742">

And also a lab for SQL which was *very* long and had to create CTE on top of CTE on top of CTE for different cases

<img width="910" alt="image" src="https://github.com/user-attachments/assets/008fa45d-07c2-4a44-a4a5-eae77e58a3e3">

Sometimes we can reduce query time by creating an index

<img width="935" alt="image" src="https://github.com/user-attachments/assets/a1293e5e-b31e-4473-ae3c-bde2248ecff8">

### Streaming queries

<img width="933" alt="image" src="https://github.com/user-attachments/assets/6e4b1656-9fb8-41d9-a703-6723364dc163">

<img width="935" alt="image" src="https://github.com/user-attachments/assets/f91f70cc-d70a-462d-a4ab-54c632b59c7e">

This part introduced AWS' managed Apache Flink services, and the lab was about using and deploying them.

<img width="892" alt="image" src="https://github.com/user-attachments/assets/aca22311-f7bd-48d2-9aaa-aefd78a4dfcb">

<img width="933" alt="image" src="https://github.com/user-attachments/assets/613a94b4-c789-4b9e-bdf5-81b591582ffa">

---

That is all for today!

See you tomorrow :)
